{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo de Maximización de la Esperanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/3/3d/EM_Process.jpg\" width=\"500px\" height=\"300px\" />\n",
    "\n",
    "\n",
    "> Con los preliminares vistos en el anterior notebook, estamos listos para entrarle a la explicación del algoritmo de maximización de la esperanza.\n",
    "\n",
    "> Este interesante algoritmo sirve para entrenar los parámetros de una gran mayoría de los modelos con variables latentes, incluido el modelo de mezclas Gaussianas.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Entender la forma general del algoritmo de maximización de la esperanza.\n",
    "> - Obtener detalladamente la elección en el paso E.\n",
    "> - Obtener detalladamente la elección en el paso M.\n",
    "\n",
    "> **Referencias:**\n",
    "> - Bayesian Methods for Machine Learning course, HSE University, Coursera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Forma general del algoritmo de maximización de la experanza\n",
    "\n",
    "Comenzamos por establecer la situación general sobre la que definiremos el algoritmo de maximización de la esperanza.\n",
    "\n",
    "Tenemos un modelo de las variables $t_i$ y $x_i$, para $i=1,\\dots,N$ ($N$ puntos de datos) de la siguiente manera:\n",
    "\n",
    "![latent](figures/latent_model.png)\n",
    "\n",
    "donde\n",
    "\n",
    "- $t_i \\in \\{1, \\dots, k\\}$: es una variable latente que determina el valor de\n",
    "- $x_i \\in \\mathbb{R}^{d}$: variable(s) medidas,\n",
    "- $\\theta$: son los parámetros del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que la verosimilitud marginal es:\n",
    "\n",
    "$$\n",
    "p(x_i | \\theta) = \\sum_{c=1}^{k} p(x_i, t_i=c | \\theta) = \\sum_{c=1}^{k} p(x_i | t_i=c, \\theta) p(t_i=c | \\theta).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como habíamos visto en nuestro ejemplo de mezclas Gaussianas, podemos maximizar la función de verosimilitud marginal (marginal porque marginalizamos respecto a la variable latente) para encontrar los parámetros:\n",
    "\n",
    "$$\n",
    "\\arg \\max_{\\theta} p(X | \\theta).\n",
    "$$\n",
    "\n",
    "Recordamos el truco común, lo anterior es igual a:\n",
    "\n",
    "$$\n",
    "\\arg \\max_{\\theta} \\log p(X | \\theta).\n",
    "$$\n",
    "\n",
    "Adicionalmente, suponiendo muestras i.i.d., tenemos que:\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(X | \\theta) &= \\sum_{i=1}^{N} \\log p(x_i | \\theta) \\\\\n",
    "                   &= \\sum_{i=1}^{N} \\log \\left(\\sum_{c=1}^{k} p(x_i, t_i=c | \\theta)\\right).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, vimos que es posible maximizar esta función usando un método numérico estándar (gradiente descendiente). Sin embargo, se introducen ciertas complejidades que queremos evitar.\n",
    "\n",
    "**¿Qué hacemos entonces?** La idea general es la siguiente:\n",
    "\n",
    "1. Encontramos una cota inferior para esta expresión usando la desigualdad de Jensen(los detalles vendrán después):\n",
    "\n",
    "    \\begin{align}\n",
    "    \\log p(X | \\theta) &= \\sum_{i=1}^{N} \\log p(x_i | \\theta) \\\\\n",
    "                       &= \\sum_{i=1}^{N} \\log \\left(\\sum_{c=1}^{k} p(x_i, t_i=c | \\theta)\\right) \\geq \\mathcal{L}(\\theta).\n",
    "    \\end{align}\n",
    "\n",
    "   Obviamente, la función $\\mathcal{L}(\\theta)$ no será cualquier cota inferior, sino una que sea sencilla de maximizar. ¿Cómo nos aseguramos que $\\mathcal{L}(\\theta)$ sea una buena elección? (explicar problemática en el pizarrón).\n",
    "   \n",
    "2. En realidad, lo que hacemos es elegir no solo una cota, sino una familia de cotas inferiores que nos permitirá elegir **la mejor cota inferior**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto, introducimos una distribución artificial positiva $q(t) > 0$ (**distribución variacional**):\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(X | \\theta) &= \\sum_{i=1}^{N} \\log p(x_i | \\theta) \\\\\n",
    "                   &= \\sum_{i=1}^{N} \\log \\left(\\sum_{c=1}^{k} p(x_i, t_i=c | \\theta)\\right) \\\\\n",
    "                   &= \\sum_{i=1}^{N} \\log \\left(\\sum_{c=1}^{k} \\underbrace{\\frac{q(t_i=c)}{q(t_i=c)}}_{1} p(x_i, t_i=c | \\theta)\\right). \\\\\n",
    "\\end{align}\n",
    "\n",
    "Recordamos la desigualdad de Jensen: \n",
    "\n",
    "> *Proposición.* Sea $f:\\Omega \\subseteq \\mathbb{R}^{k} \\to \\mathbb{R}$ una función cóncava. Entonces para cualquier selección de números $\\alpha_i \\geq 0$, con $i = 1, \\dots, m$, tales que $\\sum_{i=1}^m \\alpha_i = 1$ y cualquier selección de elementos $x_i \\in \\Omega$, con $i = 1, \\dots, m$, se tiene que:\n",
    "> \n",
    "> $$\n",
    "  f\\left(\\sum_{i=1}^{m} \\alpha_i x_i\\right) \\geq \\sum_{i=1}^m \\alpha_i f(x_i)\n",
    "  $$\n",
    "  \n",
    "Tomando en calidad de:\n",
    "- la función cóncava $f(\\cdot) = \\log(\\cdot)$,\n",
    "- los escalares no negativos $\\alpha_i = q(t_i=c)$, tales que $\\sum_{i=1}^m q(t_i=c) = 1$ ($q$ es una distribución de probabilidad,\n",
    "- los argumentos $x_i=\\frac{1}{q(t_i=c)} p(x_i, t_i=c | \\theta)$,\n",
    "\n",
    "tenemos que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\log p(X | \\theta) &= \\sum_{i=1}^{N} \\log p(x_i | \\theta) \\\\\n",
    "                   &= \\sum_{i=1}^{N} \\log \\left(\\sum_{c=1}^{k} p(x_i, t_i=c | \\theta)\\right) \\\\\n",
    "                   &= \\sum_{i=1}^{N} \\log \\left(\\sum_{c=1}^{k} \\underbrace{\\frac{q(t_i=c)}{q(t_i=c)}}_{1} p(x_i, t_i=c | \\theta)\\right) \\qquad \\text{(desigualdad de Jensen)}\\\\\n",
    "                   &\\geq \\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\log \\left(\\frac{1}{q(t_i=c)} p(x_i, t_i=c | \\theta)\\right) := \\mathcal{L}(q, \\theta).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hemos conseguido con este procedimiento es generar una familia de cotas inferiores $\\mathcal{L}(q, \\theta)$ (tenemos una cota inferior para cada distribución $q$), es decir:\n",
    "\n",
    "$$\n",
    "\\log p(X | \\theta) \\geq \\mathcal{L}(q, \\theta) \\quad \\text{para toda }q\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma, podemos elegir la mejor distribución $q$.\n",
    "\n",
    "**¿En qué sentido?**\n",
    "\n",
    "Bueno, pues una propiedad deseable es que la cota inferior \"no sea muy inferior\" a lo que estamos intentando acotar (ilustrar en el pizarrón). De manera que, dado un valor previo de los parámetros $\\theta_k$, podemos elegir la siguiente distribución $q_{k+1}$ haciendo:\n",
    "\n",
    "$$\n",
    "q^{j+1} = \\arg \\max_{q} \\mathcal{L}(q, \\theta^j) \\Rightarrow \\text{ E-step.}\n",
    "$$\n",
    "\n",
    "Una vez elegida la distribución artificial $q = q_{j+1}$, podemos elegir $\\theta$ para maximizar la cota inferior:\n",
    "\n",
    "$$\n",
    "\\theta^{j+1} = \\arg \\max_{\\theta} \\mathcal{L}(q^{j+1}, \\theta) \\Rightarrow \\text{ M-step.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, estamos aplicando una estrategia del tipo **divide y conquistarás**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una función compleja (como la <font color=red>roja</font> en la gráfica de abajo), y lo que hacemos es encontrar una función fácil de maximizar que sea una cota inferior de la función compleja (como la <font color=blue>azul</font> en la gráfica de abajo):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://upload.wikimedia.org/wikipedia/commons/3/3d/EM_Process.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. E-step\n",
    "\n",
    "Ya que conocemos la idea general, concentrémosnos en nuestro primer problema.\n",
    "\n",
    "Encontramos una familia de cotas inferiores (cota inferior variacional) de la log-verosimilitud marginal:\n",
    "\n",
    "$$\n",
    "\\log p(X | \\theta) \\geq \\mathcal{L}(q, \\theta) \\quad \\text{para toda }q\n",
    "$$\n",
    "\n",
    "y queremos encontrar la distribución $q$ que maximice:\n",
    "\n",
    "$$\n",
    "q^{j+1} = \\arg \\max_{q} \\mathcal{L}(q, \\theta^j).\n",
    "$$\n",
    "\n",
    "¿Cómo se ve esto gráficamente? (ver en el pizarrón)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera que el GAP entre la log-verosimilitud y la cota variacional es:\n",
    "\n",
    "\\begin{align}\n",
    "0 \\leq GAP & = \\log p(X | \\theta) - \\mathcal{L}(q, \\theta) \\\\\n",
    "           & = \\sum_{i=1}^{N} \\log p(x_i | \\theta) - \\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\log \\left(\\frac{p(x_i, t_i=c | \\theta)}{q(t_i=c)}\\right) \\\\\n",
    "           & = \\sum_{i=1}^{N} \\left(\\log p(x_i | \\theta) \\underbrace{\\sum_{c=1}^{k} q(t_i=c)}_{1} - \\sum_{c=1}^{k} q(t_i=c) \\log \\left(\\frac{p(x_i, t_i=c | \\theta)}{q(t_i=c)} \\right)\\right) \\\\\n",
    "           & = \\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\left(\\log p(x_i | \\theta) - \\log \\left(\\frac{p(x_i, t_i=c | \\theta)}{q(t_i=c)} \\right)\\right) \\\\\n",
    "           & = \\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\log\\left(\\frac{p(x_i | \\theta) q(t_i=c)}{p(x_i, t_i=c | \\theta)} \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Podemos simplificar la expresión $\\frac{p(x_i | \\theta)}{p(x_i, t_i=c | \\theta)}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera que\n",
    "\n",
    "\\begin{align}\n",
    "0 \\leq GAP & = \\log p(X | \\theta) - \\mathcal{L}(q, \\theta) \\\\\n",
    "           & = \\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\log\\left(\\frac{q(t_i=c)}{p(t_i=c | x_i, \\theta)} \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordamos la definición de **la divergencia de Kullback-Leibler**\n",
    "\n",
    "> *Definición.* Dadas dos distribuciones de probabilidad, la divergencia de Kullback-Leibler se define como:\n",
    ">\n",
    "> $$\n",
    "  \\mathcal{KL}(q || p) = \\sum_{x} q(x) \\log \\frac{q(x)}{p(x)} = E_{q(x)}\\left[\\log \\frac{q(x)}{p(x)}\\right]\n",
    "  $$\n",
    ">\n",
    "> si las variables son discretas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿A qué es igual la expresión $\\sum_{c=1}^{k} q(t_i=c) \\log\\left(\\frac{q(t_i=c)}{p(t_i=c | x_i, \\theta)} \\right)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así,\n",
    "\n",
    "\\begin{align}\n",
    "0 \\leq GAP & = \\log p(X | \\theta) - \\mathcal{L}(q, \\theta) \\\\\n",
    "           & = \\sum_{i=1}^{N} \\mathcal{KL}(q(t_i) || p(t_i|x_i, \\theta)).\n",
    "\\end{align}\n",
    "           \n",
    "           \n",
    "Recordando que lo que queríamos era:\n",
    "\n",
    "$$\n",
    "q^{j+1} = \\arg \\max_{q} \\mathcal{L}(q, \\theta^j) = \\arg \\min_{q} GAP(q, \\theta^j) = \\arg \\min_{q}\\sum_{i=1}^{N} \\mathcal{KL}(q(t_i) || p(t_i|x_i, \\theta^j))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, la divergencia tiene las siguientes propiedades:\n",
    "\n",
    "1. $\\mathcal{KL}(q || q) = 0$\n",
    "2. $\\mathcal{KL}(q || p) \\geq 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, para minimizar lo anterior, hacemos:\n",
    "\n",
    "$$\n",
    "q^{j+1}(t_i) = p(t_i|x_i, \\theta^j)\n",
    "$$\n",
    "\n",
    "con lo cual obtenemos **el óptimo global**. Es decir, debemos elegir la distribución variacional como la distribución posterior $p(t_i|x_i, \\theta^j)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Qué implica que $GAP=0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. M-step\n",
    "\n",
    "Ahora, centramos nuestra atención en el segundo problema.\n",
    "\n",
    "Entonces, podemos resumir nuestro camino hasta acá de la siguiente manera:\n",
    "\n",
    "1. Encontramos la cota inferior variacional para la log-verosimilitud marginal:\n",
    "\n",
    "   $$\n",
    "   \\log p(X | \\theta) \\geq \\mathcal{L}(q, \\theta) = \\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\log \\left(\\frac{p(x_i, t_i=c | \\theta)}{q(t_i=c)}\\right).\n",
    "   $$\n",
    "   \n",
    "2. Encontramos la mejor cota inferior respecto a la distribución artificial $q$, teniendo los parámetros fijos (E-step):\n",
    "   \n",
    "   $$\n",
    "   q^{j+1}(t_i) = \\arg \\max_{q} \\mathcal{L}(q, \\theta^j) =  p(t_i|x_i, \\theta^j).\n",
    "   $$\n",
    "\n",
    "3. Ahora, queremos encontrar el máximo de esta mejor cota inferior respecto a los parámetros $\\theta$ (dejando fija la distribución $q^{j+1}$ que recién hallamos):\n",
    "\n",
    "   $$\n",
    "   \\theta^{j+1} = \\arg \\max_{\\theta} \\mathcal{L}(q^{j+1}, \\theta)\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajemos con la expresión de $\\mathcal{L}$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(q, \\theta) & = \\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\log \\left(\\frac{p(x_i, t_i=c | \\theta)}{q(t_i=c)}\\right) \\\\\n",
    "                       & = \\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\log \\left(p(x_i, t_i=c | \\theta)\\right) - \\underbrace{\\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\log \\left(q(t_i=c)\\right)}_{\\text{no depende de }\\theta}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera que:\n",
    "\n",
    "\\begin{align}\n",
    "\\arg \\max_{\\theta} \\mathcal{L}(q, \\theta) & = \\arg \\max_{\\theta} \\sum_{i=1}^{N} \\sum_{c=1}^{k} q(t_i=c) \\log \\left(p(x_i, t_i=c | \\theta)\\right) \\\\\n",
    "                                          & = \\arg \\max_{\\theta} \\sum_{i=1}^{N} \\mathbb{E}_{q(t_i)} \\left[\\log p(x_i, t_i| \\theta)\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comúnmente, tendremos que la función de verosimilitud $p(x_i, t_i| \\theta)$ es cóncava respecto a los parámetros (por ejemplo, una Gaussiana), y tiene un único máximo global fácil de encontrar (analíticamente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, **el algoritmo de maximización de la esperanza** se resume como sigue:\n",
    "\n",
    "- Para $j=1, 2, \\dots$, repetir hasta la convergencia:\n",
    "\n",
    "  1. E-step:\n",
    "     \n",
    "     $$\n",
    "     q^{j+1}(t_i) = p(t_i|x_i, \\theta^j).\n",
    "     $$\n",
    "     \n",
    "  2. M-step\n",
    "      \n",
    "      $$\n",
    "      \\theta^{j+1} = \\arg \\max_{\\theta} \\sum_{i=1}^{N} \\mathbb{E}_{q^{j+1}(t_i)} \\left[\\log p(x_i, t_i| \\theta)\\right]\n",
    "      $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Propiedades de convergencia\n",
    "\n",
    "Ya tenemos las expresiones para nuestro algoritmo. Ahora nace la pregunta, ¿Qué tan bueno es?\n",
    "\n",
    "Supongamos que estamos en la iteración $j=old$ en la gráfica siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://upload.wikimedia.org/wikipedia/commons/3/3d/EM_Process.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, en el *E-step* encontramos la mejor cota variacional (<font color=blue>curva azul</font>) $\\mathcal{L}(q^{new}, \\theta)$, la cual, en el *M-step*, maximizamos respecto a los parámetros, obteniendo $\\theta^{new}$. Entonces:\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(X | \\theta^{new}) & \\geq \\mathcal{L}(q^{new}, \\theta^{new}) \\quad (\\text{porque } \\mathcal{L} \\text{ es una cota inferior}) \\\\\n",
    "                         & \\geq \\mathcal{L}(q^{new}, \\theta^{old}) \\quad (\\text{porque } \\theta^{new} \\text{ es el máximo de la cota variacional}) \\\\\n",
    "                         & = \\log p(X | \\theta^{old}) \\quad (\\text{porque } GAP=0)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que acabamos de demostrar, es que a cada iteración del **algoritmo de maximización de la esperanza** siempre obtenemos un mejores parámetros (por lo menos no peores) que los que teníamos.\n",
    "\n",
    "Por tanto, la convergencia a un punto crítico está asegurada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resumiendo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El algoritmo de **maximización de la esperanza** es un método para entrenar modelos de variable latente:\n",
    "\n",
    "  ![](figures/latent_model.png)\n",
    "\n",
    "- Dividimos un problema complejo de optimización en dos problemas más simples:\n",
    "  1. Encontramos la distribución variacional que resulte en la mejor cota inferior para nuestra log-verosimilitud.\n",
    "     - E-step:\n",
    "       \n",
    "       $$\n",
    "       q^{j+1}(t_i) = p(t_i|x_i, \\theta^j)\n",
    "       $$\n",
    "  2. Encontramos los parámetros que maximicen la mejor cota variacional.\n",
    "     - M-step:\n",
    "       \n",
    "       $$\n",
    "       \\theta^{j+1} = \\arg \\max_{\\theta} \\sum_{i=1}^{N} \\mathbb{E}_{q^{j+1}(t_i)} \\left[\\log p(x_i, t_i| \\theta)\\right]\n",
    "       $$\n",
    "- Convergencia garantizada a un máximo local.\n",
    "\n",
    "- Nos ayuda con restricciones complejas: $\\Sigma_c \\succ 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, este algoritmo se puede extender:\n",
    "\n",
    " - Restricción de las posibles distribuciones variacionales $q$.\n",
    " - Muestreo en el M-Step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¡Suficientes matemáticas por hoy! Apliquemos este algoritmo a un ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
